//
// The output of a spike evaluating Prometheus on ECS backed by EFS.
//

= Prometheus vs. AWS: An Evaluation of Storage Options
Les I'Anson
5th June 2017
:copyright: CC BY-SA 4.0
:backend: revealjs
:revealjs_theme: black
:revealjs_controls: false
:revealjs_progress: false
:revealjs_slideNumber: 'c/t'
:revealjs_history: true
:revealjs_transition: none
:revealjs_transitionSpeed: fast
:revealjs_backgroundTransition: none
:revealjs_width: '100%'
:revealjs_height: '100%'
:revealjs_margin: 0.1
:revealjs_minScale: 0.2
:revealjs_maxScale: 1.5
:customcss: custom.css


== Disclaimer

This talk is not intended to tell you everything you need to know about AWS' storage options; it merely highlights a few *key points you need to consider when deploying disk I/O intensive workloads to AWS*.

There's also a *focus on EFS*, because it was the most new to us when we set out on this journey [.small]#(you should already be comfortable with EIS and EBS)#.

I am by no means an expert, *everything I say might be wrong*; hopefully it's not, but do you own research and please tell me if it is.


== What is Prometheus?

Prometheus is an open-source monitoring system and time series database originally developed at SoundCloud, which is *very I/O intensive*.

[NOTE.speaker]
--
.That's All You Need To Know
That's all you need to know for the purposes of this talk.
--


== The Storage Performance Triangle

*Throughput* [.small]#(typically measured in MB/s)#, the average sequential data transfer speed.

*IOPS* [.small]#(I/O operations per second)#, the amount of random read or write operations that can be done in one second.

*Latency* [.small]#(typically measured in ms)#, how long it takes for an I/O task to begin.

[NOTE.speaker]
--
.3 Factors
These are the three parts that when combined tell the full story of storage performance.

.It's Own Talk
This is worthy of a talk all on its own.

.Sequential vs. Random
High throughput is especially important for workloads that are sequential in nature.
High IOPS are especially important for workloads that are random in nature.

.A Few Large Files vs. Many Small Files
Here's a grossly oversimplified example of how two workloads accessing the same amount of data require significantly different amounts of IOPS.
The first workload requires reading ten 500MB files, 5GB and it takes 100 seconds for the transfer to complete.
This means that the transfer rate is 50MB/s and consumes 10 IOPS, which is well within the capabilities of a single hard disk.
The second workload requires reading ten thousand 500KB files, the same amount of data, 5GB, but it consumes 10,000 IOPS.
Since the typical disk drive can't achieve more than 100-200 IOPS, this request won't get done in the same 100 seconds.
This is an example of how different workloads demand significantly different performance characteristics, while using the same storage capacity.

.IOPS = Throughput
A certain amount of IOPS equates to a certain amount of throughput depending on I/O size (512 bytes to 4KB, 8KB, 16KB, 32KB...).
Obviously the bigger the I/O size the more throughput that's required.

.The Physical World = Latency
Latency is measured in milliseconds (ms) and should be as low as possible.
Moving data slowly from one system to another reduces performance, but the time it takes for the data to begin moving, when no useful work is being done, is also a huge factor.
There are several factors that would affect latency, physical limits of mechanical spinning disks and the distance between each hosts and the SAN, etc.
SSD arrays virtually eliminate seek time from the equation, as such other variables like controller firmware and prower efficiency far more important.
The raw speed of flash memory means that bad storage controller and storage software implementations can no longer hide behind the poor performance of traditional, spinning hard disk drives. 
--


== Some Perspective

SATA-300 7,200rpm HDD *~50-100 MB/s 100-200 IOPS* [.small]#(approx. writes, depending on track location, etc.)#

PCIe NVMe SSD *1,000+ MB/s 10,000+ IOPS* [.small]#(approx. writes, depending on NAND technology, etc.)#

[NOTE.speaker]
--
[quote, https://en.wikipedia.org/wiki/Hard_disk_drive_performance_characteristics]
____
As of 2010, a typical 7200 RPM desktop HDD has a "disk-to-buffer" data transfer rate up to 1030 Mbit/s [128.75MB/s]. This rate depends on the track location, so it will be higher on the outer zones (where there are more data sectors per track) and lower on the inner zones (where there are fewer data sectors per track); and is generally somewhat higher for 10,000 RPM drives.
____
--


== Time Series I/O

[quote, https://coreos.com/blog/prometheus-2.0-storage-layer-optimization]
____
...time series read access patterns are vastly different from write patterns. Any useful storage layer for such a system must deliver high performance for both cases.
____

As a result, only *directly attached PCIe NVMe SSDs* are recommended +
by Brian Brazil & Co.

[NOTE.speaker]
--
.Small, Random I/O
Lots of small random read/writes.

.EC2 Instance Store
AWS offers these in the form of https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html[EC2 Instance Store].
--


== AWS Storage Offerings

image::aws-storage-platforms_2017-06-05.png[]

[NOTE.speaker]
--
.File, Object & Block
Shows the three main categories of AWS storage; file, object and block.

.Options Considered
. Single EC2 Instance + Instance Store
. Single Self-Healing EC2 Instance + EBS
. ECS + EFS
--


== EC2 Instance Store

*_Ephemeral* NVMe SSDs physically attached to the Xen host._

 * *Non-persistent*, they only exist for the life of the instance.
 * Data *not replicated* by default, but you can do your own replication.
 * *No* out of the box *snapshot/backup* functionality, but again you can add your own.
 * Check out the NVMe SSD backed, high I/O i3 instances for insane workloads.


== EFS

_File Server as a Service, specifically *NFS as a Service*._

* *Multi-attach/parallel I/O* from tens-thousands of EC2 instances.
* *Multi-AZ* availability/durability.
* *Automatic* GB-PT *scaling* (grow/shrink).
* GB/s throughput [.small]#(we'll come to that)#.
* *All for $0.30/GB/m* [.small]#($0.33/GB/m in eu-west-1:Ireland)#.

[NOTE.speaker]
--
.No Windows Support
It's NFS based so there's no (official) Windows support for EFS, but who cares.

.Trade offs
Sounds wonderful, but as we will see, all this convince comes at a price.
--


== EFS Trivia
 
The service is only available in the five largest AWS regions [.small]#namely, us-east-1:N. Virginia, us-east-2:Ohio, us-west-2:Oregon, eu-west-1:Ireland and ap-southeast-2:Sydney#, because, similar to RDS Aurora, *EFS requires three live AZs in a region* to satisfy its durability SLA.

[NOTE.speaker]
--
.3 AZs Regardless
Your data is automatically replicated over three AZs (regardless of the number of AZs you create a network share across) for increased durability.
--


== EFS Throughput Scaling

[quote, https://docs.aws.amazon.com/efs/latest/ug/performance.html]
____
image::aws-efs-throughput-scaling_2017-06-05.png[]
____

[NOTE.speaker]
--
.Throughput vs. Size of EFS File System
Therefore, you need to find the expected throughput for your application and then adjust the size of the EFS file system accordingly.

.50MB/s = 1TB Example
For example, if you require a baseline throughput of 50MB/s you will need an EFS file system size of 1TB; however, if your application only stores 10GB of data in EFS, you will have to create dummy files on your EFS file system in order to increase its size.

.No Other Pricing Model
AWS does not offer a way to pay for more throughput, but I guess this makes sense in the interests of a simple pricing model; however, I personally think AWS have this wrong, because EFS is piratically unusable for file systems under 1TB (50MB/s).

.PCIe NVMe SSD Yardstick
Note, we have no baseline throughput/IOPS figures for Prometheus at a global, region or organisation level, so we're using directly attached PCIe NVMe SSDs as our yardstick.
--


== EFS Performance Modes

TL;DR, _General Purpose_ mode for lowest latency, _Max I/O_ mode for parallel scale-out.

[NOTE.speaker]
--
.General Purpose vs. Highly Parallelised
EFS has two performance modes, General Purpose Performance and Max I/O Performance.

. General Purpose is the AWS recommended default as it covers the needs of most applications.
. Max I/O has the capacity to scale to higher levels of aggregate throughput and IOPS but at the cost of higher latencies per file operation, making it suitable for highly parallelised workloads only.
--


== The Golden Rule

The size of your EFS file system should be determined by *throughput not capacity*.


== The How

Similar to an S3 bucket, *you do not set the size of your EFS volume when you create it*, you simply pay for what you use; however, EFS delivers throughput [.small]#(via a baseline and a temporary burst capacity "burst credits")# based on the size of the file system.

`dd if=/dev/zero of=/mnt/efs/foo bs=1M count=1048576 # within the first 24hrs`

[NOTE.speaker]
--
.2TB Tier for 1st 24hrs
When you first create an EFS volume, AWS gives you the 2TB tier for the first 24hrs at the cost of the base tier, which is the ideal time to dd those "dummy files" to increase baseline throughput and burst credit accumulation.

.Many EFS User Do Not Understand EFS
There is a huge thread entitled https://forums.aws.amazon.com/thread.jspa?threadID=235976[_AWS EFS slow response_], which has hundreds of posts from users who do not grok this.
--


== SSD-Grade Performance?

A good rule of thumb is *~100MB/s of throughput per 2TB stored*, so ~1000MB/s [.small]#(PCIe NVMe SSD territory)# requires 20TB @ $6,000 p/m [.small]#(in zeros)#; however:

[quote, https://docs.aws.amazon.com/efs/latest/ug/limits.html]
____
The maximum throughput you can drive per Amazon EC2 instance is 250 MB/s.
____

So, *you have to parallelise across multiple instances* to achieve anything like SSD levels of performance.

[NOTE.speaker]
--
.EFS Costs @ $0.30/GB/m
* 500KB/s = 10GB @ $3/m
* 5MB/s = 100GB @ $30/m
* 50MB/s = 1TB @ $300/m
* 100MB/s = 2TB @ $600/m
* 1GB/s = 20TB @ $6,000/m
* 5GB/s = 100TB @ $30,000/m
* 10GB/s = 200TB @ $60,000/m
* 50GB/s = 1PB @ $300,000/m

.TCO: EFS vs. GlusterFS
Seems expensive; however, $300/m for the 1TB tier is good value for money versus the headache of running your own storage clusters on EC2 using something like GlusterFS for example.
--


== EFS Trivia

When you mount an EFS partition on an EC2 instance, the volume size shows up as *`9007199254740992KB`* (~9EB), which at *$0.30/GB* per month would cost you *$2.7 billion per month* if you filled it!

[NOTE.speaker]
--
.9 Exabytes
Just over nine Exabytes.

.US Million != UK Million
That's 2.7 billion, assuming a billion is a thousand million (US style) and not a million millions (UK style) and 1EB costs three-hundred million per month.
--


== Latency vs. Consistency

When performing a write, data is written to all three AZs before you receive the ACK.

`mount -t nfs4 *-o async* \ +
file-system-id.efs.aws-region.amazonaws.com:/ efs-mount-point`

[NOTE.speaker]
--
.3x AZ Replication = Latency
The distributed architecture of EFS has some other performance implications, namely the latency.
There's a latency overhead for each file operation due to replication between AZs and strong consistency.

.Untested async Option
We haven't yet tested/benchmarked the `async` option.
--


== EFS Marketing Blurb

[quote, https://docs.aws.amazon.com/efs/latest/ug/performance.html]
____
Amazon EFS file systems are distributed across an unconstrained number of storage servers enabling file systems to grow elastically to petabyte scale... This distributed data storage design means that multithreaded applications and applications that concurrently access data from multiple Amazon EC2 instances can drive substantial levels of aggregate throughput and IOPS... This distributed architecture results in a small latency overhead for each file operation. Due to this per-operation latency, overall throughput generally increases as the average I/O size increases, because the overhead is amortized over a larger amount of data.
____

[NOTE.speaker]
--
.Parallelised Workloads Only Please
What this basically means is that EFS requires highly parallelised workloads (i.e concurrent operations from multiple threads across multiple EC2 instances), to drive high levels of aggregate throughput and IOPS.

.No Single Instance Benchmarks @ 2016 re:Invent
Indeed benchmarks lifted from https://www.youtube.com/watch?v=PlTuJx4VnGw[AWS re:Invent 2016: Deep Dive on Amazon Elastic File System (STG202), Published 2/12/2016] seems to support this, whereby all figures are based on https://www.gnu.org/software/parallel/[GNU parallel] (multiple threads) running across multiple instances and any single instance figures are omitted. 

.GNU parallel Only Please
It remains to be seen how EFS will perform with serial processing of high volumes of small files, my hunch is poorly.
--


== Prometheus on EFS

[quote, Brian Brazil Re: https://github.com/prometheus/prometheus/issues/2805]
____
We strongly recommend not using NFS or other networked filesystems.
We support working POSIX filesystems, and recommend they be local for reliability and performance.
NFS is not known for being a working POSIX filesystem.
____


== Test, Retest & Test Again!

You can read all the blurb you like, but *there's no substitute for testing your workload*.

`level=error msg="Opening storage failed: read meta information /prometheus/01BHMHCQ64M68EATD9YAZTAH29: open /prometheus/01BHMHCQ64M68EATD9YAZTAH29/meta.json: no such file or directory" source="main.go:89"`

[NOTE.speaker]
--
.Your Millage May Vary
AWS is a moving target, your millage may vary.
--


== if (EFS) {

* Parallelise [.small]#(e.g. GNU parallel)#.
* Aggregate I/O [.small]#(i.e. fewer large files over many small files)#.
* Perform async operations [.small]#(i.e. not waiting for the writes to propagate to disk/all AZs, obviously being aware of the usual data consistency pitfalls)#.
* Cache [.small]#(more pitfalls to consider)#.
* Monitor `BurstCreditBalance` and `PermittedThroughput` CloudWatch metrics.
* Check your application support.

[NOTE.speaker]
--
.Look For Opportunities
When considering EFS, you need to look for opportunities to...
--


== EBS

_Block Storage as a Service._

* Volumes *persist* independently of EC2 instances.
* Can be *attached, detached and reattached* to EC2 instances.  
* Can only be attached to *one instance at a time*, but *many volumes* can be attached to an instance.
* Just like bare metal, they support *software RAID* [.small]#(i.e. RAID 0 for greater I/O performance or RAID 1 for on-instance redundancy)#.


== EBS Cont.

* Support *snapshotting* out of the box.
* Support *encryption* out of the box [.small]#(data at rest, data in flight, snapshots, everything basically)#.
* Volumes are specific to an AZ, where each block is *replicated within the same AZ* [.small]#(across the SAN presumably)#.

[NOTE.speaker]
--
.AWS' SAN
Effetely AWS' SAN as a Service

.Multiple Volumes Avoid Hotspots
Multiple volumes for separating boot volumes from data volumes (i.e. boot, root, data/home, logs, swap, etc.) are recommended to avoid hotspots.
--


== EBS Gives You Options

* SSD-backed volumes `gp2` [.small]#(general purpose)# and `io1` [.small]#(provisioned IOPS)#.
* HDD-backed volumes `st1` [.small]#(throughput optimised)# and `sc1` [.small]#(cold, very cheap)#.
* EBS-optimised instances [.small]#(dedicated network bandwidth for EBS I/O)#.

[NOTE.speaker]
--
[quote, http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html]
____
General Purpose SSD (gp2) volumes offer cost-effective storage that is ideal for a broad range of workloads. These volumes deliver single-digit millisecond latencies and the ability to burst to 3,000 IOPS for extended periods of time. Between a minimum of 100 IOPS (at 33.33 GiB and below) and a maximum of 10,000 IOPS (at 3,334 GiB and above), baseline performance scales linearly at 3 IOPS per GiB of volume size. A gp2 volume can range in size from 1 GiB to 16 TiB.

{blank}[...]

Provisioned IOPS SSD (io1) volumes are designed to meet the needs of I/O-intensive workloads, particularly database workloads, that are sensitive to storage performance and consistency. Unlike gp2, which uses a bucket and credit model to calculate performance, an io1 volume allows you to specify a consistent IOPS rate when you create the volume, and Amazon EBS delivers within 10 percent of the provisioned IOPS performance 99.9 percent of the time over a given year.

{blank}[...]

Throughput Optimized HDD (st1) volumes provide low-cost magnetic storage that defines performance in terms of throughput rather than IOPS. This volume type is a good fit for large, sequential workloads such as Amazon EMR, ETL, data warehouses, and log processing. Bootable st1 volumes are not supported.

{blank}[...]

Cold HDD (sc1) volumes provide low-cost magnetic storage that defines performance in terms of throughput rather than IOPS. With a lower throughput limit than st1, sc1 is a good fit ideal for large, sequential cold-data workloads. If you require infrequent access to your data and are looking to save costs, sc1 provides inexpensive block storage. Bootable sc1 volumes are not supported.
____

.Bucket/Burst Credit Model + Volume Size vs. Pre-provisioned IOPS
Unlike gp2, which uses a bucket and burst credit model based on the size of the volume to calculate performance, an io1 volume allows you to specify a consistent IOPS rate when you create the volume, and Amazon EBS delivers within 10 percent of the provisioned IOPS performance 99.9 percent of the time over a given year.

.Remember: IOPS = Throughput
A certain amount of IOPS equates to a certain amount of throughput depending on I/O size (512 bytes to 4KB, 8KB, 16KB, 32KB...).
Obviously the bigger the I/O size the more throughput that's required.

.Example: 10,000 IOPS * 16KB = 160MB/s
Everything is measured and benchmarked against a 16KB block size, so up to 10,000 IOPS on a `gp2` at 16KB 10,000 IOPS * 16KB = 160MB/s maximum throughput.

.Single Pipe vs. Dedicated EBS Pipe vs. 10Gb/s
A standard c3.2xlarge has about ~125Mb/s of network throughput allocated to it, but that bandwidth is used for everything, an EBS-optimised instance gives you dedicated bandwidth (between ~500Mbps and ~10,000Mbps, depending on the instance type) specifically to the EBS.
This is enabled by default on c4, d2, m4, p2, and x1 instances or you can run a 10Gb/s instance.

.sc1 < S3
`sc1` costs less than S3.

.CloudWatch Metrics Resolution
Also note that when looking at CloudWatch 900,000 IOPS over 5 minutes = 3000 IOPS.
--


== EBS AFR

EBS is designed for *99.999%* [.small]#(five nines)# service availability [.small]#(i.e. access to your volumes)#, which equates to a *0.1-0.2% AFR* [.small]#(Annual Failure Rate)#, so if you run ~1000 EBS volumes constantly for a year, you can expect to loose one or two, which is why you *take snapshots* [.small]#&mdash; point in time backups to S3, which is multi-AZ and has *99.999999999%* (eleven nines) of durability#.

[NOTE.speaker]
--
.5x 9s
Five nines service availability.

.Snapshots Backed By S3
EBS snapshots are a point-in-time backup of modified blocks, stored in S3, accessed via EBS APIs.
Subsequent snapshots are incremental.

.From Snapshot To New AMI, New AZ, New Volume, New Account, Public Data Set, AMI Marketplace.
From a snapshot you can create an AMI, you can create new volumes in different AZs, you can also increase the size of a volume, you can copy them to other regions, other accounts (a common DR strategy is to keep golden images of all your keep applications and move them around for disaster recovery), you can also share snapshots between other accounts or publicly, in fact there are a wealth of public data sets (genomic, census, global weather, transport) that are available as snapshots, the AMI Marketplace (i.e. CentOS, Debian images) are all backed by EBS snapshots.
--


== EC2 Auto-Recovery

*EBS enables EC2 auto-recovery* via the per-instance CloudWatch metric `StatusCheckFailed_System` that triggers `RECOVER`. Instances retain, instance ID, instance metadata, private IP addresses, elastic IP addresses and *EBS volume attachments*.

Supported on C3, C4, M3, M4, P2, R3, T2 and X1 instances only [.small]#(i.e. instance types with EBS-only storage)#.

[NOTE.speaker]
--

.System Status (Physical Xen Host) vs. Instance Status (VM)
[quote, http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/monitoring-system-instance-status-check.html]
____
There are two types of status checks: system status checks and instance status checks.

System Status Checks

Monitor the AWS systems on which your instance runs. These checks detect underlying problems with your instance that require AWS involvement to repair. When a system status check fails, you can choose to wait for AWS to fix the issue, or you can resolve it yourself. For instances backed by Amazon EBS, you can stop and start the instance yourself, which migrates it to a new host computer. For instances backed by instance store, you can terminate and replace the instance.

The following are examples of problems that can cause system status checks to fail:

* Loss of network connectivity
* Loss of system power
* Software issues on the physical host
* Hardware issues on the physical host that impact network reachability

*Instance Status Checks*

Monitor the software and network configuration of your individual instance. These checks detect problems that require your involvement to repair. When an instance status check fails, typically you will need to address the problem yourself (for example, by rebooting the instance or by making instance configuration changes).

The following are examples of problems that can cause instance status checks to fail:

* Failed system status checks
* Incorrect networking or startup configuration
* Exhausted memory
* Corrupted file system
* Incompatible kernel
____

.StatusCheckFailed_Instance = Churn
While `StatusCheckFailed_Instance` is a bit too aggressive for auto-recovery, it might prove useful in certain circumstances.
--


== Storage Conclusion

*EC2 Instance Store is always going to be faster than EBS*; however, EBS gives you persistence independent of EC2 instances, block replication [.small]#(within the same AZ)#, snapshotting and encryption.

*EBS is always going to be faster than EFS*; however, EFS gives you multi-attach/parallel I/O, mutli-AZ replication and virtually unlimited elasticity [.small]#(but saying no up-front provisioning/capacity planning would be a misnomer)#.


== Prometheus Conclusion

[quote, Anthony Mazzarella (MLBAM)]
____
It's a cloud native monitoring system that needs to run on big, bare-metal box.
____

However, Prometheus' _"performance"_ obviously depends on many factors, the number of targets, the resolution, the queries you're running, etc., which should be *tuned based on metrics* [.small]#(ignoring the obvious _chicken or the egg_ dilemma)#.


== AWS Resources

* https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html
* https://docs.aws.amazon.com/efs/latest/ug/limits.html
* https://docs.aws.amazon.com/efs/latest/ug/performance.html
* https://aws.amazon.com/efs/pricing/
* http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html
* http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumeTypes.html

[NOTE.speaker]
--
Thankfully AWS offers some good documentation on all this.
--


== Prometheus Resources

* https://github.com/prometheus/prometheus/issues/2805
* https://coreos.com/blog/prometheus-2.0-storage-layer-optimization
* https://docs.google.com/document/d/1lRKBaz9oXI5nwFZfvSbPhpwzUbUr3-9qryQGG1C6ULk
* https://docs.google.com/spreadsheets/d/1sMQe9oOKhMhIVw9WmuCEWdPtAoccJ4a-IuZv4fXDHxM

[NOTE.speaker]
--
Mostly benchmarks.
--


== Thank you!

https://github.com/les/prometheus-vs-aws
